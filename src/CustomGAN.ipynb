{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Umpmg0t79Q8O"
   },
   "outputs": [],
   "source": [
    "nx = 400 # number of grid points in the horizontal direction\n",
    "nz = 400 # number of grid points in the vertical direction\n",
    "dd = 5.0 # grid cell size\n",
    "nt = 1000 # number of time samples to be modeled\n",
    "dt = 0.0005 # time step\n",
    "srcx = 900 # source horizontal location in meters\n",
    "srcz = 800 # source vertical location in meters\n",
    "\n",
    "nabs = 40 # number of absorbing cells on the boundary\n",
    "a = 0.0053 # strength of sponge layer\n",
    "FreeSurf=False # free surface condition of top (False for now)\n",
    "\n",
    "vp = np.arange(2000,4500,(4500-2000)/nz)\n",
    "vp = np.tile(np.expand_dims(vp,0),[nx,1]) # just coming up with a velocity model\n",
    "\n",
    "#vp = np.ones((nx,nz))*3000.0\n",
    "\n",
    "time = np.arange(0,nt*dt,dt) # time vector\n",
    "f0 = 15. # central frequency of the wavelet\n",
    "t0 = 1/f0 # a shift to make sure wavelet is causal\n",
    "wav  = (1.0-2.0*np.power(np.pi*f0*(time-t0),2))*np.exp(-np.power(np.pi*f0*(time-t0),2)) # computing the wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_input(vp, wave, time, srcx, srcz, dd):\n",
    "#     dd = int(dd)\n",
    "#     srcx = srcx // dd\n",
    "#     srcz = srcz // dd\n",
    "#     wave += 1\n",
    "#     out_channels = len(time)\n",
    "#     vp_out = np.zeros((out_channels, vp.shape[0], vp.shape[1]))\n",
    "#     for i in range(out_channels):\n",
    "#         vp_temp = np.copy(vp)\n",
    "#         vp_temp[srcx, srcz] *= wave[i]\n",
    "#         vp_out[i] = vp_temp\n",
    "#     return vp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input(vp, wave, time, srcx, srcz, dd):\n",
    "    dd = int(dd)\n",
    "    srcx = srcx // dd\n",
    "    srcz = srcz // dd\n",
    "    wave += 1\n",
    "    vp_out = np.copy(vp)\n",
    "    vp_out[srcx, srcz] *= wave.max()\n",
    "    return vp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = make_input(vp, wav, time, srcx, srcz, dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFwajQ3tGgI2"
   },
   "outputs": [],
   "source": [
    "# class Generator(nn.Module):\n",
    "#     '''\n",
    "#     Generator Class\n",
    "#     Values:\n",
    "#         z_dim: the dimension of the noise vector, a scalar\n",
    "#         im_chan: \n",
    "#         hidden_dim: the inner dimension, a scalar\n",
    "#     '''\n",
    "#     def __init__(self, z_dim=400*400, im_chan=1000, hidden_dim=32000):\n",
    "#         super(Generator, self).__init__()\n",
    "#         self.z_dim = z_dim\n",
    "#         # Build the neural network\n",
    "#         self.gen = nn.Sequential(\n",
    "#             self.make_gen_block(z_dim, hidden_dim * 4, kernel_size=4), #4x4\n",
    "#             self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=2, stride=3), #11x11\n",
    "#             self.make_gen_block(hidden_dim * 2, hidden_dim, kernel_size=3, stride=3), #33x33\n",
    "#             self.make_gen_block(hidden_dim, hidden_dim // 2, kernel_size=4, stride=3), #100x100\n",
    "#             self.make_gen_block(hidden_dim // 2, hidden_dim // 4, kernel_size=4, stride=2, padding=1), #200x200\n",
    "#             self.make_gen_block(hidden_dim // 4, im_chan, kernel_size=2, stride=2, final_layer=True) #400x400\n",
    "#         )\n",
    "\n",
    "#     def make_gen_block(self, input_channels, output_channels, kernel_size=3, \n",
    "#                        stride=2, padding=0, final_layer=False):\n",
    "#         '''\n",
    "#         Function to return a sequence of operations corresponding to a generator block of DCGAN;\n",
    "#         a transposed convolution, a batchnorm (except in the final layer), and an activation.\n",
    "#         Parameters:\n",
    "#             input_channels: how many channels the input feature representation has\n",
    "#             output_channels: how many channels the output feature representation should have\n",
    "#             kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n",
    "#             stride: the stride of the convolution\n",
    "#             padding: the padding of the convolution\n",
    "#             final_layer: a boolean, true if it is the final layer and false otherwise \n",
    "#                       (affects activation and batchnorm)\n",
    "#         '''\n",
    "#         if not final_layer:\n",
    "#             return nn.Sequential(\n",
    "#                 nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, padding),\n",
    "#                 nn.BatchNorm2d(output_channels),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#             )\n",
    "#         else:\n",
    "#             return nn.Sequential(\n",
    "#                 nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, padding),\n",
    "#                 nn.Tanh(),\n",
    "#             )\n",
    "\n",
    "#     def forward(self, noise):\n",
    "#         '''\n",
    "#         Function for completing a forward pass of the generator: Given a noise tensor,\n",
    "#         returns generated images.\n",
    "#         Parameters:\n",
    "#             noise: a noise tensor with dimensions (n_samples, z_dim)\n",
    "#         '''\n",
    "# #         x = noise.view(len(noise), self.z_dim, 1, 1)\n",
    "#         x = noise.view(self.z_dim, 1, 1)\n",
    "#         return self.gen(x)\n",
    "\n",
    "# def get_noise(n_samples, z_dim, device='cpu'):\n",
    "#     '''\n",
    "#     Function for creating noise vectors: Given the dimensions (n_samples, z_dim)\n",
    "#     creates a tensor of that shape filled with random numbers from the normal distribution.\n",
    "#     Parameters:\n",
    "#       n_samples: the number of samples to generate, a scalar\n",
    "#       z_dim: the dimension of the noise vector, a scalar\n",
    "#       device: the device type\n",
    "#     '''\n",
    "#     noise = torch.FloatTensor(make_input(vp, wav, time, srcx, srcz, dd))\n",
    "#     return noise.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    '''\n",
    "    Generator Class\n",
    "    Values:\n",
    "        z_dim: the dimension of the noise vector, a scalar\n",
    "        im_chan: \n",
    "        hidden_dim: the inner dimension, a scalar\n",
    "    '''\n",
    "    def __init__(self, z_dim=1, im_chan=1000, hidden_dim=32000):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        # Build the neural network\n",
    "        self.gen = nn.Sequential(\n",
    "            self.make_gen_block(z_dim, hidden_dim * 4, kernel_size=4), #4x4\n",
    "            self.make_gen_block(hidden_dim * 4, hidden_dim * 2, kernel_size=2, stride=3), #11x11\n",
    "            self.make_gen_block(hidden_dim * 2, hidden_dim, kernel_size=3, stride=3), #33x33\n",
    "            self.make_gen_block(hidden_dim, hidden_dim // 2, kernel_size=4, stride=3), #100x100\n",
    "            self.make_gen_block(hidden_dim // 2, hidden_dim // 4, kernel_size=4, stride=2, padding=1), #200x200\n",
    "            self.make_gen_block(hidden_dim // 4, im_chan, kernel_size=2, stride=2, final_layer=True) #400x400\n",
    "        )\n",
    "\n",
    "    def make_gen_block(self, input_channels, output_channels, kernel_size=3, \n",
    "                       stride=2, padding=0, final_layer=False):\n",
    "        '''\n",
    "        Function to return a sequence of operations corresponding to a generator block of DCGAN;\n",
    "        a transposed convolution, a batchnorm (except in the final layer), and an activation.\n",
    "        Parameters:\n",
    "            input_channels: how many channels the input feature representation has\n",
    "            output_channels: how many channels the output feature representation should have\n",
    "            kernel_size: the size of each convolutional filter, equivalent to (kernel_size, kernel_size)\n",
    "            stride: the stride of the convolution\n",
    "            padding: the padding of the convolution\n",
    "            final_layer: a boolean, true if it is the final layer and false otherwise \n",
    "                      (affects activation and batchnorm)\n",
    "        '''\n",
    "        if not final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, padding),\n",
    "                nn.BatchNorm2d(output_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.ConvTranspose2d(input_channels, output_channels, kernel_size, stride, padding),\n",
    "                nn.Tanh(),\n",
    "            )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        '''\n",
    "        Function for completing a forward pass of the generator: Given a noise tensor,\n",
    "        returns generated images.\n",
    "        Parameters:\n",
    "            noise: a noise tensor with dimensions (n_samples, z_dim)\n",
    "        '''\n",
    "#         x = noise.view(len(noise), self.z_dim, 1, 1)\n",
    "        x = noise\n",
    "        return self.gen(x)\n",
    "\n",
    "def get_noise(n_samples, z_dim, device='cpu'):\n",
    "    '''\n",
    "    Function for creating noise vectors: Given the dimensions (n_samples, z_dim)\n",
    "    creates a tensor of that shape filled with random numbers from the normal distribution.\n",
    "    Parameters:\n",
    "      n_samples: the number of samples to generate, a scalar\n",
    "      z_dim: the dimension of the noise vector, a scalar\n",
    "      device: the device type\n",
    "    '''\n",
    "    noise = torch.FloatTensor(make_input(vp, wav, time, srcx, srcz, dd))\n",
    "    return noise.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
